{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Data Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the vanilla dataset\n",
    "df_matches = pd.read_csv('epl-training.csv')\n",
    "\n",
    "# Importing Data File\n",
    "df_matches = pd.read_csv('epl-training.csv')\n",
    "\n",
    "# Ensure the match date is in datetime format\n",
    "df_matches['Date'] = pd.to_datetime(df_matches['Date'],dayfirst = True)\n",
    "\n",
    "# Sort the df_matches dataframe by ascending date order\n",
    "df_matches = df_matches.sort_values(by='Date', ascending=True).reset_index(drop=True)\n",
    "\n",
    "# Drop any rows where all the values are nan\n",
    "df_matches = df_matches.dropna()\n",
    "\n",
    "df_matches.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Travel Distance and Travel Fatigue Index\n",
    "\n",
    "# Stadium Coordinates\n",
    "stadium_coordinates = {\n",
    "    'Swansea': (51.6428, -3.9347),\n",
    "    'West Ham': (51.5383, -0.0166),\n",
    "    'Charlton': (51.4865, 0.0368),\n",
    "    'Wigan': (53.5477, -2.6542),\n",
    "    'Wolves': (52.5904, -2.1306),\n",
    "    'Brighton': (50.8609, -0.0801),\n",
    "    'Bournemouth': (50.7352, -1.8384),\n",
    "    'Blackpool': (53.8046, -3.0483),\n",
    "    \"Nott'm Forest\": (52.9399, -1.1326),\n",
    "    'Aston Villa': (52.5092, -1.8851),\n",
    "    'Brentford': (51.4908, -0.2888),\n",
    "    'Chelsea': (51.4816, -0.1910),\n",
    "    'Coventry': (52.4481, -1.4956),\n",
    "    'Sheffield United': (53.3703, -1.4708),\n",
    "    'Fulham': (51.4749, -0.2216),\n",
    "    'Leeds': (53.7775, -1.5721),\n",
    "    'Middlesbrough': (54.5781, -1.2178),\n",
    "    'Newcastle': (54.9756, -1.6218),\n",
    "    'Luton': (51.8842, -0.4316),\n",
    "    'Leicester': (52.6203, -1.1422),\n",
    "    'Hull': (53.7465, -0.3680),\n",
    "    'Huddersfield': (53.6543, -1.7684),\n",
    "    'Southampton': (50.9058, -1.3911),\n",
    "    'QPR': (51.5093, -0.2322),\n",
    "    'Bradford': (53.8042, -1.7590),\n",
    "    'Everton': (53.4387, -2.9662),\n",
    "    'Blackburn': (53.7286, -2.4894),\n",
    "    'Man United': (53.4631, -2.2914),\n",
    "    'Stoke': (52.9884, -2.1754),\n",
    "    'Reading': (51.4222, -0.9828),\n",
    "    'Birmingham': (52.4756, -1.8682),\n",
    "    'Liverpool': (53.4308, -2.9610),\n",
    "    'Tottenham': (51.6044, -0.0664),\n",
    "    'Ipswich': (52.0544, 1.1455),\n",
    "    'Norwich': (52.6221, 1.3091),\n",
    "    'Watford': (51.6498, -0.4016),\n",
    "    'Man City': (53.4830, -2.2002),\n",
    "    'Crystal Palace': (51.3983, -0.0855),\n",
    "    'Derby': (52.9149, -1.4473),\n",
    "    'Burnley': (53.7888, -2.2302),\n",
    "    'Sunderland': (54.9146, -1.3884),\n",
    "    'West Brom': (52.5090, -1.9639),\n",
    "    'Arsenal': (51.5549, -0.1084),\n",
    "    'Portsmouth': (50.7964, -1.0639),\n",
    "    'Cardiff': (51.4729, -3.2041),\n",
    "    'Bolton': (53.5805, -2.5357)\n",
    "}\n",
    "\n",
    "# Define Haversine function\n",
    "def haversine(coord1, coord2):\n",
    "    lon1, lat1 = coord1\n",
    "    lon2, lat2 = coord2\n",
    "\n",
    "    R = 6371000  # radius of Earth in meters\n",
    "    phi_1 = math.radians(lat1)\n",
    "    phi_2 = math.radians(lat2)\n",
    "\n",
    "    delta_phi = math.radians(lat2 - lat1)\n",
    "    delta_lambda = math.radians(lon2 - lon1)\n",
    "\n",
    "    a = math.sin(delta_phi / 2.0) ** 2 + math.cos(phi_1) * math.cos(phi_2) * math.sin(delta_lambda / 2.0) ** 2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "\n",
    "    meters = R * c  # output distance in meters\n",
    "    km = meters / 1000.0  # output distance in kilometers\n",
    "\n",
    "    return round(km, 3)\n",
    "\n",
    "# Calculate travel distance\n",
    "def calculate_travel_distance(row, stadium_coordinates):\n",
    "    home_team = row['HomeTeam']\n",
    "    away_team = row['AwayTeam']\n",
    "    if home_team in stadium_coordinates and away_team in stadium_coordinates:\n",
    "        home_coords = stadium_coordinates[home_team]\n",
    "        away_coords = stadium_coordinates[away_team]\n",
    "        return haversine(home_coords, away_coords)\n",
    "    return None  # Handle missing coordinates\n",
    "\n",
    "# Apply the function to calculate travel distances\n",
    "df_matches['TravelDistance'] = df_matches.apply(\n",
    "    calculate_travel_distance, axis=1, args=(stadium_coordinates,)\n",
    ")\n",
    "\n",
    "# Normalize Travel Distance to create a Travel Fatigue Index\n",
    "min_distance = df_matches['TravelDistance'].min()\n",
    "max_distance = df_matches['TravelDistance'].max()\n",
    "\n",
    "# Apply Travel Fatigue Index to the Dataframe\n",
    "df_matches['TravelFatigueIndex'] = (df_matches['TravelDistance'] - min_distance) / (\n",
    "    max_distance - min_distance\n",
    ")\n",
    "\n",
    "# Display a sample of the updated dataset\n",
    "display(df_matches[['HomeTeam', 'AwayTeam', 'TravelDistance', 'TravelFatigueIndex']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Manager Information\n",
    "\n",
    "df_managers = pd.read_excel('PremierLeagueManagers.xlsx')\n",
    "\n",
    "# Ensure Season_Start and Season_End are in datetime format\n",
    "df_managers['Season_Start'] = pd.to_datetime(df_managers['Season_Start'],dayfirst = True)\n",
    "df_managers['Season_End'] = pd.to_datetime(df_managers['Season_End'],dayfirst = True)\n",
    "\n",
    "# Ensure Season_Start and Season_End are in datetime format\n",
    "df_managers['Season_Start'] = pd.to_datetime(df_managers['Season_Start'],dayfirst = True)\n",
    "df_managers['Season_End'] = pd.to_datetime(df_managers['Season_End'],dayfirst = True)\n",
    "\n",
    "# Function to get the manager for a specific team and match date\n",
    "def get_manager(team, match_date):\n",
    "    manager_row = df_managers[\n",
    "        (df_managers['Club'] == team) &\n",
    "        (df_managers['Season_Start'] <= match_date) &\n",
    "        (df_managers['Season_End'] >= match_date)\n",
    "    ]\n",
    "    return manager_row['Manager'].iloc[0] if not manager_row.empty else None\n",
    "\n",
    "# Add HomeManager and AwayManager columns to df_matches\n",
    "df_matches['HomeManager'] = df_matches.apply(lambda row: get_manager(row['HomeTeam'], row['Date']), axis=1)\n",
    "df_matches['AwayManager'] = df_matches.apply(lambda row: get_manager(row['AwayTeam'], row['Date']), axis=1)\n",
    "\n",
    "# Importing Spending Information\n",
    "\n",
    "df_spending = pd.read_excel('Spending_data.xlsx')\n",
    "\n",
    "# Ensure Season_Start and Season_End are in datetime format\n",
    "df_spending['Season_Start'] = pd.to_datetime(df_spending['Season_Start'],dayfirst = True)\n",
    "df_spending['Season_End'] = pd.to_datetime(df_spending['Season_End'],dayfirst = True)\n",
    "\n",
    "# Ensure Season_Start and Season_End are in datetime format\n",
    "df_spending['Season_Start'] = pd.to_datetime(df_spending['Season_Start'],dayfirst = True)\n",
    "df_spending['Season_End'] = pd.to_datetime(df_spending['Season_End'],dayfirst = True)\n",
    "\n",
    "# Function to get the expenditure for a specific team and match date\n",
    "def get_spending(team, match_date):\n",
    "    spending_row = df_spending[\n",
    "        (df_spending['Team'] == team) &\n",
    "        (df_spending['Season_Start'] <= match_date) &\n",
    "        (df_spending['Season_End'] >= match_date)\n",
    "    ]\n",
    "    return spending_row['Expenditure'].iloc[0] if not spending_row.empty else 0\n",
    "\n",
    "# Add HomeManager and AwayManager columns to df_matches\n",
    "df_matches['HomeExpenditure'] = df_matches.apply(lambda row: get_spending(row['HomeTeam'], row['Date']), axis=1)\n",
    "df_matches['AwayExpenditure'] = df_matches.apply(lambda row: get_spending(row['AwayTeam'], row['Date']), axis=1)\n",
    "\n",
    "# Display a sample of the updated dataset\n",
    "display(df_matches[['HomeTeam', 'AwayTeam','HomeManager','AwayManager','HomeExpenditure' ,'AwayExpenditure', 'TravelDistance', 'TravelFatigueIndex']].head(10))\n",
    "\n",
    "df_matches.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the distribution of FTR Values\n",
    "print(df_matches['FTR'].value_counts()) # Raw values\n",
    "print(df_matches['FTR'].value_counts(normalize=True)*100) # Percentage of the results being H, A, or D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Data Transformation & Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Rolling Average Statistics\n",
    "k = 38 # Number of matches to look backwards to.\n",
    "\n",
    "# Function to Calculate Rolling Average Statistics for the Past k Matches. Each row's kAvg does not include the current results.\n",
    "def generate_kAvg(df, attribute, HomeTeam=True):\n",
    "    if HomeTeam:\n",
    "        group_by_team = \"HomeTeam\"\n",
    "    elif not HomeTeam:\n",
    "        group_by_team = \"AwayTeam\"\n",
    "    \n",
    "    kattribute = \"k\" + attribute\n",
    "    df[kattribute] = (\n",
    "    df.groupby(group_by_team)[attribute]     # Group by HomeTeam or AwayTeam\n",
    "    .transform(lambda x: x.shift(1).rolling(window=k, min_periods=1).mean())  # Shift by 1 to exclude the current match, and create a rolling window of up to k past matches\n",
    "    )\n",
    "    df[kattribute] = df[kattribute].fillna(0) # Filling nan values with 0\n",
    "\n",
    "Home_kAvg_features = ['FTHG','HTHG','HS','HC','HF','HY','HR']\n",
    "Away_kAvg_features = ['FTAG','HTAG','AS','AC','AF','AY','AR']\n",
    "\n",
    "for feature in Home_kAvg_features:\n",
    "    generate_kAvg(df_matches, feature,True)\n",
    "for feature in Away_kAvg_features:\n",
    "    generate_kAvg(df_matches, feature,False)\n",
    "    \n",
    "display(df_matches)\n",
    "\n",
    "# Create a new column to store home wins and away wins\n",
    "df_matches['HomeWin'] = (df_matches['FTR'] == 'H').astype(int)\n",
    "df_matches['AwayWin'] = (df_matches['FTR'] == 'A').astype(int)\n",
    "\n",
    "# Calculate rolling win rate for home games\n",
    "df_matches['HomeWinRate'] = (\n",
    "    df_matches.groupby('HomeTeam')['HomeWin']    # Group by HomeTeam\n",
    "    .cumsum()                                    # Cumulative sum of home wins\n",
    "    / df_matches.groupby('HomeTeam').cumcount()  # Divide by cumulative games played\n",
    "    .add(1)                                      # To avoid division by zero\n",
    ")\n",
    "\n",
    "# Calculate rolling win rate for away games\n",
    "df_matches['AwayWinRate'] = (\n",
    "    df_matches.groupby('AwayTeam')['AwayWin']    # Group by AwayTeam\n",
    "    .cumsum()                                    # Cumulative sum of away wins\n",
    "    / df_matches.groupby('AwayTeam').cumcount()  # Divide by cumulative games played\n",
    "    .add(1)                                      # To avoid division by zero\n",
    ")\n",
    "\n",
    "# Display relevant columns\n",
    "display(df_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5; # Number of matches to look back for this particular home and away pair\n",
    "\n",
    "def generate_nAvg_pairwise(df, row, attribute):\n",
    "    # Getting the matches with the current row's home and away team lineup\n",
    "    matches = df[ (df['HomeTeam'] == row['HomeTeam']) & (df['AwayTeam'] == row['AwayTeam']) ]\n",
    "    \n",
    "    # Get the current index of the row\n",
    "    current_index = row.name\n",
    "    \n",
    "    # Get previous matches before this match\n",
    "    previous_matches = matches[matches.index < current_index]\n",
    "    \n",
    "    return (\n",
    "        previous_matches[attribute]\n",
    "        .rolling(window=n, min_periods=1)\n",
    "        .mean()\n",
    "        .iloc[-1]  # Get the latest rolling average value\n",
    "        if not previous_matches.empty\n",
    "        else 0  # Default value for no previous matches\n",
    "    )\n",
    "# List of attributes to calculate team pair specific rolling averages for\n",
    "attributes = ['FTHG','HTHG','HS','HC','HF','HY','HR',\n",
    "              'FTAG','HTAG','AS','AC','AF','AY','AR']\n",
    "\n",
    "for attribute in attributes:\n",
    "    # Defining new columns for the specific combination\n",
    "    new_column = f\"n{attribute}_Pairwise\"\n",
    "    df_matches[new_column] = df_matches.apply(\n",
    "        lambda row: generate_nAvg_pairwise(df_matches, row, attribute), axis = 1\n",
    "    )\n",
    "\n",
    "# Showing what columns are present in the current dataframe\n",
    "df_matches.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team Names\n",
    "le_teams = LabelEncoder()\n",
    "\n",
    "# Using the same label encoder for the home and away teams.\n",
    "le_teams.fit(pd.concat([df_matches['HomeTeam'],df_matches['AwayTeam']])) \n",
    "\n",
    "# Using the label encoder to encode the home and away teams\n",
    "df_matches['HomeTeam_Encoded'] = le_teams.transform(df_matches['HomeTeam'])\n",
    "df_matches['AwayTeam_Encoded'] = le_teams.transform(df_matches['AwayTeam'])\n",
    "\n",
    "# FTR and HTR\n",
    "le_results = LabelEncoder()\n",
    "le_results.fit(pd.concat([df_matches['FTR'],df_matches['HTR']]))\n",
    "\n",
    "# Using the label encoder to encode the FTR and HTR\n",
    "df_matches['FTR_Encoded'] = le_results.transform(df_matches['FTR'])\n",
    "df_matches['HTR_Encoded'] = le_results.transform(df_matches['HTR'])\n",
    "\n",
    "# Referee\n",
    "le_referee = LabelEncoder()\n",
    "le_referee.fit(df_matches['Referee'])\n",
    "\n",
    "df_matches['Referee_Encoded'] = le_referee.transform(df_matches['Referee'])\n",
    "\n",
    "# Managers\n",
    "le_managers = LabelEncoder() \n",
    "le_managers.fit(pd.concat([df_matches['HomeManager'],df_matches['AwayManager']]))\n",
    "df_matches['HomeManager_Encoded'] = le_managers.transform(df_matches['HomeManager'])\n",
    "df_matches['AwayManager_Encoded'] = le_managers.transform(df_matches['AwayManager'])\n",
    "\n",
    "display(df_matches)\n",
    "df_matches = df_matches.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the input features \n",
    "input_features = ['HomeTeam_Encoded','AwayTeam_Encoded','HomeManager_Encoded',\n",
    "                 'AwayManager_Encoded','Referee_Encoded', 'HomeExpenditure', 'AwayExpenditure', \n",
    "                  'TravelDistance', 'TravelFatigueIndex',\n",
    "                  'kFTHG', 'kHTHG','kHS', 'kHC', 'kHF', 'kHY', \n",
    "                  'kHR', 'kFTAG', 'kHTAG', 'kAS', 'kAC', 'kAF', 'kAY', 'kAR', \n",
    "                  'HomeWinRate', 'AwayWinRate', \n",
    "                  'nFTHG_Pairwise', 'nHTHG_Pairwise', 'nHS_Pairwise', 'nHC_Pairwise',\n",
    "                   'nHF_Pairwise', 'nHY_Pairwise', 'nHR_Pairwise', 'nFTAG_Pairwise',\n",
    "                   'nHTAG_Pairwise', 'nAS_Pairwise', 'nAC_Pairwise', 'nAF_Pairwise',\n",
    "                   'nAY_Pairwise', 'nAR_Pairwise']\n",
    "df_input = df_matches[input_features]\n",
    "display(df_input)\n",
    "\n",
    "output_features = ['FTR_Encoded']\n",
    "df_output = df_matches['FTR_Encoded']\n",
    "display(df_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking correlation Matrix\n",
    "correlation_matrix = pd.concat([df_input, df_output], axis=1).corr()\n",
    "\n",
    "sorted_correlation = correlation_matrix['FTR_Encoded'].abs().sort_values(ascending = False)\n",
    "\n",
    "display(sorted_correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the Referee_Encoded column\n",
    "df_input = df_input.drop('Referee_Encoded', axis = 1)\n",
    "input_features.remove(\"Referee_Encoded\")\n",
    "\n",
    "# Display the finalised input feature list\n",
    "display(df_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Methodology Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into training and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "testing_size = 0.33\n",
    "input_train, input_test, output_train, output_test = train_test_split(df_input, df_output, test_size=testing_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the input training and test data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "input_train_scaled = scaler.fit_transform(input_train)\n",
    "input_test_scaled = scaler.transform(input_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Model Training & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Final Predictions on Test Set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ucl_cs_module",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
